[
{
	"uri": "//localhost:1313/2_getting-started/0_self_paced.html",
	"title": "...on your own",
	"tags": [],
	"description": "",
	"content": "Running the workshop on your own Only complete this section if you are running the workshop on your own. If you are at an AWS hosted event (such as re:Invent, Kubecon, Immersion Day, etc), go to Start the workshop at an AWS event. Otherwise, click the Next arrow to the install steps.\n"
},
{
	"uri": "//localhost:1313/2_getting-started/0_self_paced/01_account.html",
	"title": "Create an AWS IAM User with Cloudformation",
	"tags": [],
	"description": "",
	"content": "Note: Only complete this section if you are running the workshop on your own. If you are at an AWS hosted event (such as re:Invent, Kubecon, Immersion Day, etc), go to Start the workshop at an AWS event. Keep in mind, you may incur costs by participating in this workshop. Please navigate to the ../Cleanup\nYour account must have the ability to create new IAM Users and scope other IAM permissions.\nNavigate to Cloudformation and click on Create Stack -\u0026gt; With new resources standard. Select \u0026ldquo;Build from Infrastructure Composer\u0026rdquo;: Click Template: Copy/Paste the Cloudformation template below into the blank field:\nAWSTemplateFormatVersion: \u0026#39;2010-09-09\u0026#39; Description: \u0026#39;Create IAM User with Access Key stored in Secrets Manager and Bedrock permissions\u0026#39; Resources: MyIAMUser: Type: AWS::IAM::User Properties: UserName: ServiceNow_User ManagedPolicyArns: - !Ref BedrockUserPolicy BedrockUserPolicy: Type: AWS::IAM::ManagedPolicy Properties: ManagedPolicyName: BedrockUserPolicy PolicyDocument: Version: \u0026#39;2012-10-17\u0026#39; Statement: - Effect: Allow Action: - bedrock:InvokeModel - bedrock:ListFoundationModels - bedrock:GetFoundationModel - bedrock:ListCustomModels - bedrock:GetCustomModel - bedrock:ListModelInvocationLoggingConfigurations - bedrock:ListPromptsForCustomModel - bedrock:ListPromptTemplates - bedrock:GetPromptTemplate Resource: \u0026#39;*\u0026#39; - Effect: Allow Action: - iam:PassRole Resource: \u0026#39;*\u0026#39; Condition: StringEquals: iam:PassedToService: bedrock.amazonaws.com MyIAMUserAccessKey: Type: AWS::IAM::AccessKey Properties: UserName: !Ref MyIAMUser MySecret: Type: AWS::SecretsManager::Secret Properties: Name: MyUserAccessKey Description: \u0026#39;Access key for ServiceNow_User\u0026#39; StoreSecretFunction: Type: AWS::Lambda::Function Properties: Runtime: python3.8 Handler: index.handler Role: !GetAtt LambdaExecutionRole.Arn Code: ZipFile: | import boto3 import cfnresponse def handler(event, context): try: if event[\u0026#39;RequestType\u0026#39;] == \u0026#39;Create\u0026#39;: secret_name = event[\u0026#39;ResourceProperties\u0026#39;][\u0026#39;SecretName\u0026#39;] access_key_id = event[\u0026#39;ResourceProperties\u0026#39;][\u0026#39;AccessKeyId\u0026#39;] secret_access_key = event[\u0026#39;ResourceProperties\u0026#39;][\u0026#39;SecretAccessKey\u0026#39;] secrets_manager = boto3.client(\u0026#39;secretsmanager\u0026#39;) secrets_manager.put_secret_value( SecretId=secret_name, SecretString=\u0026#39;{\u0026#34;AccessKeyId\u0026#34;:\u0026#34;\u0026#39; + access_key_id + \u0026#39;\u0026#34;,\u0026#34;SecretAccessKey\u0026#34;:\u0026#34;\u0026#39; + secret_access_key + \u0026#39;\u0026#34;}\u0026#39; ) cfnresponse.send(event, context, cfnresponse.SUCCESS, {}) except Exception as e: print(e) cfnresponse.send(event, context, cfnresponse.FAILED, {}) StoreSecretCustomResource: Type: Custom::StoreSecret Properties: ServiceToken: !GetAtt StoreSecretFunction.Arn SecretName: !Ref MySecret AccessKeyId: !Ref MyIAMUserAccessKey SecretAccessKey: !GetAtt MyIAMUserAccessKey.SecretAccessKey LambdaExecutionRole: Type: AWS::IAM::Role Properties: AssumeRolePolicyDocument: Version: \u0026#39;2012-10-17\u0026#39; Statement: - Effect: Allow Principal: Service: lambda.amazonaws.com Action: sts:AssumeRole ManagedPolicyArns: - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole Policies: - PolicyName: SecretsManagerAccess PolicyDocument: Version: \u0026#39;2012-10-17\u0026#39; Statement: - Effect: Allow Action: - secretsmanager:PutSecretValue Resource: !Ref MySecret Outputs: SecretsManagerLink: Description: \u0026#34;Link to the Credentials in AWS Secrets Manager\u0026#34; Value: !Sub \u0026#34;https://${AWS::Region}.console.aws.amazon.com/secretsmanager/home?region=${AWS::Region}#!/secret?name=${MySecret}\u0026#34; Click create template: Click confirm template: Click Next: Specify the stack name and click next: Scroll down the page and click the checkbox and click next: Scroll down and click Submit: Navigate to Outputs and click on the SecretsManagerLink which will direct you to the IAM access-key and Secret: Click on retrieve secret value and copy the secret access id and secret access key to a notepad: Success! Now you can wait for the instructions provided by the instructor to continue the workshop!\n"
},
{
	"uri": "//localhost:1313/1_introduction/11_foreword.html",
	"title": "Foreword",
	"tags": [],
	"description": "",
	"content": "Foreword Submodule One Heading This paragraph block should be an explanation of an existing problem and how the partner has worked to achieve a solution for it. Example content guidance can be found at the bottom of this page.\n**REMOVE:** With the exception of _index.md, the module folders and filenames should be changed to better reflect their content, i.e. 1_Planning as the folder and 11_HowToBegin as the first submodule. Changing the \"weight\" value of the header is ultimately what reflects the order the modules are presented. Next Section Heading This paragraph block can optionally be utilized to lead into the next section of the workshop.\nExample Content Guidance The nature of software development has fundamentally changed Teams and organizations are releasing code at a record breaking pace and only getting faster. This is primarily attributed to these teams adopting and implementing modern concepts and practices, such as Continuous Delivery, Continuous Integration/Deployments (CI/CD) and DevOps into their software development processes. These modern concepts enable teams to better align development and delivery efforts resulting in teams collaborating around code and an increased awareness among collaborators no matter their role.\n"
},
{
	"uri": "//localhost:1313/1_introduction.html",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Introduction Learning Objectives This paragraph block should highlight the learning objectives of the workshop. A bulleted list works well for this purpose.\nWorkshop Structure This paragraph block should be utilized to briefly explain the submodules that are going to be presented as well as the approximate total time for the workshop and individual submodules. For example:\nPrerequisites *(15 minutes)* Setting up an account for the solution *(15 minutes)* Module 1: Module 1 Title *(30 minutes)* Module 2: Module 2 Title *(30 minutes)* Module 3: Module 3 Title *(30 minutes)* **REMOVE:** With the exception of _index.md, the module folders and filenames should be changed to better reflect their content, i.e. 1_Planning as the folder and 11_HowToBegin as the first submodule. Changing the \"weight\" value of the header is ultimately what reflects the order the modules are presented. REMOVE: Every introduction page should include the following warning label.\nThe examples and sample code provided in this workshop are intended to be consumed as instructional content. These will help you understand how various AWS services can be architected to build a solution while demonstrating best practices along the way. These examples are not intended for use in production environments.\nNext Section Heading This paragraph block can optionally be utilized to lead into the next section of the workshop.\n"
},
{
	"uri": "//localhost:1313/2_getting-started/1_aws_event.html",
	"title": "...at an AWS event",
	"tags": [],
	"description": "",
	"content": "Attending an AWS hosted event To complete this workshop, you will be provided with an AWS account via the AWS Workshop Studio. A team hash will be provided to you by event staff. Included in this environment will be a IAM User created along with a set of Access Keys.\nIf you are currently logged in to an AWS Account, you can log out using this link\nLogging into Workshop Studio Dashboard Connect to the portal by clicking the button or browsing to https://catalog.us-east-1.prod.workshops.aws/. The following screen shows up. Enter the provided hash in the text box.\nThe page shows the event details and presents the Terms and Conditions of the workshop. Review and check the box at the bottom of the page if you agree, then click the Join event button.\nYour event dashboard should be presented. On the left margin, click the \u0026ldquo;Open AWS console\u0026rdquo; link.\nThis account will expire at the end of the workshop and all the resources created will be automatically de-provisioned. You will not be able to access this account after today.\nNext step Once you have completed the step above, navigate to Cloudformation and click on Outputs and click on the SecretsManagerLink which will direct you to the IAM access-key and Secret: Click on retrieve secret value and copy the secret access id and secret access key to a notepad: Success! Now you can wait for the instructions provided by the instructor to continue the workshop!\n"
},
{
	"uri": "//localhost:1313/1_introduction/12_technicalissue_problem.html",
	"title": "Technical Issue / Problem",
	"tags": [],
	"description": "",
	"content": "Technical Issue / Problem Submodule Two Heading This paragraph block should be an introduction to the technical issue the solution is facing. An example of this can be seen at the bottom of this page. **REMOVE:** With the exception of _index.md, the module folders and filenames should be changed to better reflect their content, i.e. 1_Planning as the folder and 11_HowToBegin as the first submodule. Changing the \"weight\" value of the header is ultimately what reflects the order the modules are presented. Next Section Heading This paragraph block can optionally be utilized to lead into the next section of the workshop.\nExample of content guidance Deploy Without Worry Deployments with Kubernetes? Kubernetes (k8s) is a container orchestration platform allowing organizations to scale their services and workloads quickly. If you are working with containers or microservices, k8s may be a great use case for you. Kubenetes deployments are container image deployments which target k8s-based environments.\nAmazon has released a managed k8s service called Elastic Kubernetes Service (EKS). Amazon EKS helps you provide highly-available and secure clusters and automates key tasks such as patching, node provisioning, and updates. While AWS provides the platform on which to run your containerize applications deploying them in a scalable, repeatable and reliable way is where Harness comes in.\nHow does Harness help with EKS deployments? Harness has first-class support for Kubernetes Resources. Harness can create scaffolding around Kubernetes Resources removing complexities around crafting your own resource definitions that are purpose made for deployments. Harness can offer granular deployment lifecycle support around different Kubernetes Resources supporting canary and blue/green deployments inside Kubernetes.\nWhy is Canary deployment tricky with EKS deployments? Canary Deployments are a progressive delivery pattern for rolling out releases to a subset of users. Canary Deployments can be complex because of the multiple phases and the judgment call of when to promote or rollback a canary. The Harness Platform has smart verification taking away the manual toil in verification and enables seamless Canary Deployments.\n"
},
{
	"uri": "//localhost:1313/2_getting-started/2_enable-bedrock-models.html",
	"title": "Enable Amazon Bedrock in the Console",
	"tags": [],
	"description": "Enable access to Amazon Bedrock foundation models using the AWS Management Console.",
	"content": "Enable Amazon Bedrock Models in the AWS Console Before we interact with Amazon Bedrock through the ServiceNow application, we need to enable access to the foundation models (FMs) you\u0026rsquo;d like to use.\nüìç Prerequisite: You should have already deployed the CloudFormation template and obtained your IAM credentials. If not, go back to the Getting Started section.\nStep 1: Sign in to the AWS Console Make sure you\u0026rsquo;re in the N. Virginia (us-east-1) region ‚Äî this is where Amazon Bedrock is fully supported. Step 2: Open Amazon Bedrock Click here or within the Search bar at the top of the AWS Console, type \u0026ldquo;Bedrock\u0026rdquo; and click on Amazon Bedrock from the dropdown.\nIf prompted to enable the service, click Enable access.\nStep 3: Enable Foundation Model Access In the left navigation menu, click Model access. Click the Manage model access button.\nSelect the following models (these are required for this workshop):\nAnthropic Claude 3 Amazon Titan Text G1 AI21 Labs Jurassic-2 Mistral 7B Click Next, then Submit to confirm model access.\nWait for the access to be granted ‚Äî this may take a few minutes.\nStep 4: Verify Access After a few minutes, return to the Model access page and ensure the status for each selected model says Access granted.\n‚úÖ You\u0026rsquo;re Ready! You‚Äôve now enabled the Bedrock models required for the rest of the workshop.\n‚û°Ô∏è Continue to Setting Up the ServiceNow Application\n"
},
{
	"uri": "//localhost:1313/",
	"title": "Partner Setup",
	"tags": [],
	"description": "",
	"content": "Partner Setup Module Three Heading This paragraph block should be an introduction to the module about requirements the partner may need for their audience members. Examples include signing up for the partner platform or installing an agent.\nModule Three Subheading This paragraph block should be utilized to briefly explain the submodules. Partner Setup Instructions A brief overview of submodule one.\n**REMOVE:** With the exception of _index.md, the module folders and filenames should be changed to better reflect their content, i.e. 1_Planning as the folder and 11_HowToBegin as the first submodule. Changing the \"weight\" value of the header is ultimately what reflects the order the modules are presented. REMOVE: Every introduction page should include the following warning label.\nThe examples and sample code provided in this workshop are intended to be consumed as instructional content. These will help you understand how various AWS services can be architected to build a solution while demonstrating best practices along the way. These examples are not intended for use in production environments.\nNext Section Heading This paragraph block can optionally be utilized to lead into the next section of the workshop.\n"
},
{
	"uri": "//localhost:1313/1_introduction/13_whoweare.html",
	"title": "Who We Are",
	"tags": [],
	"description": "",
	"content": "Who Are We? Submodule Three Heading This paragraph block should be a brief introduction to the partner, their history, goals, partnerships, and accolades. **REMOVE:** With the exception of _index.md, the module folders and filenames should be changed to better reflect their content, i.e. 1_Planning as the folder and 11_HowToBegin as the first submodule. Changing the \"weight\" value of the header is ultimately what reflects the order the modules are presented. Next Section Heading This paragraph block can optionally be utilized to lead into the next section of the workshop.\n"
},
{
	"uri": "//localhost:1313/2_getting-started/3_servicenow-enterprise-license.html",
	"title": "ServiceNow Enterprise License",
	"tags": [],
	"description": "",
	"content": "You will need ServiceNow Enterprise License to execute this workshop.\nDuring a hosted event such as re:Invent, Kubecon, Immersion Day, or any other event hosted by AWS or ServiceNow, you will be provided with a temporary License for ServiceNow Enterprise.\nIf you are NOT in a hosted event, you can get a ServiceNow Enterprise License by contacting ServiceNow Sales here\nIf you DONT supply ServiceNow Enterprise License keys , you may not be able to use all the modules of the workshop as some features will be disabled.\nThe license will be provided as a JSON by the host. Save the license text (in JSON format)provided to you in a file named as license.json on your Cloud9 Terminal.\n"
},
{
	"uri": "//localhost:1313/1_introduction/14_workshopprerequisites.html",
	"title": "Workshop Prerequisites",
	"tags": [],
	"description": "",
	"content": "Workshop Prerequisites Submodule Four Heading This paragraph block should be an introduction to the submodule. Are there any prerequisites the user must perform to begin the workshop? Do they need to sign up for any external accounts or install any tools? An example of content guidance can be found at the bottom of this page.\n**REMOVE:** With the exception of _index.md, the module folders and filenames should be changed to better reflect their content, i.e. 1_Planning as the folder and 11_HowToBegin as the first submodule. Changing the \"weight\" value of the header is ultimately what reflects the order the modules are presented. Next Section Heading This paragraph block can optionally be utilized to lead into the next section of the workshop.\nExample of content guidance Workshop Prerequisites There are some prerequisites required for completing this workshop.\nCreate a GitHub account Create a Docker Hub account Create an AWS account Some of these may be skipped if you already have the required accounts and tools.\n"
},
{
	"uri": "//localhost:1313/2_getting-started.html",
	"title": "Prerequisites",
	"tags": [],
	"description": "",
	"content": "Getting Started To start the workshop, Click on \u0026ldquo;at an AWS event\u0026rdquo; in the drop-down or Next for Self-Paced Instructions. Keep in mind that you may incur costs participating in this workshop.\n"
},
{
	"uri": "//localhost:1313/1_introduction/15_nextsteps.html",
	"title": "Workshop Next Steps",
	"tags": [],
	"description": "",
	"content": "Workshop Next Steps Submodule Five Heading This paragraph block should be an brief explanation of the next steps to take after the prerequisites have been set up. Diagrams or code samples can be shown to give a visual explanation of what will be taking place during the building of the solution. An example of content guidance can be found at the bottom of this page.\n**REMOVE:** With the exception of _index.md, the module folders and filenames should be changed to better reflect their content, i.e. 1_Planning as the folder and 11_HowToBegin as the first submodule. Changing the \"weight\" value of the header is ultimately what reflects the order the modules are presented. Next Section Heading This paragraph block can optionally be utilized to lead into the next section of the workshop.\nExample of content guidance Configuring Your Solution While working through the workshop modules, you will progressively build a 3-tier web application by utilizing core AWS services. We will provide you with any code examples and any directions specific to the set up approach we will be utilizing. Some of these may be skipped if you already have the required accounts and tools.\n"
},
{
	"uri": "//localhost:1313/4_servicenow-setup/1_setup_genai_controller_for_bedrock.html",
	"title": "Configure Generative AI Controller for Bedrock LLMs",
	"tags": [],
	"description": "",
	"content": "Configure Generative AI Controller for Bedrock LLMs In this section we are going to get started with Generative AI Controller to integrate directly with Amazon Bedrock. With Workflow Studio and Virtual Agent Designer, you can create your own use cases for AI-generated text and sentiment analysis, including advanced workflows and custom scripts.\nAI limitations This application uses artificial intelligence (AI) and machine learning, which are rapidly evolving fields of study that generate predictions based on patterns in data. As a result, this application may not always produce accurate, complete, or appropriate information. Further, there is no guarantee that this application has been fully trained or tested for your use case. To mitigate these issues, it is your responsibility to test and evaluate your use of this application for accuracy, harm, and appropriateness for your use case, employ human oversight of output, and refrain from relying solely on AI-generated outputs for decision-making purposes. This is especially important if you choose to deploy this application in areas with consequential impacts such as healthcare, finance, legal, employment, security, or infrastructure. You agree to abide by ServiceNow‚Äôs AI Acceptable Use Policy, which may be updated by ServiceNow.\nData processing This application requires data to be transferred from ServiceNow customers\u0026rsquo; individual instances to a centralized ServiceNow environment, which may be located in a different data center region from the one where your instance is, and potentially to a third-party cloud provider, such as Microsoft Azure. This data is handled per ServiceNow\u0026rsquo;s internal policies and procedures, including our policies available through our CORE Compliance Portal.\nData collection ServiceNow collects and uses the inputs, outputs, and edits to outputs of this application to develop and improve ServiceNow technologies including ServiceNow models and AI products. Customers can opt out of future data collection at any time, as described in the Now Assist Opt-Out page.\n"
},
{
	"uri": "//localhost:1313/4_servicenow-setup/1_setup_genai_controller_for_bedrock/1.1_configure_api_credentials.html",
	"title": "Configure API Credentials for Amazon Bedrock",
	"tags": [],
	"description": "",
	"content": "Configure API Credentials for Amazon Bedrock In this section you are going to configure your API credentials (created in Getting Started \u0026gt; section) to use AWS Bedrock in custom workflows and Virtual Agent Designer topics.\nTo use Amazon Bedrock as your LLM provider for Generative AI Controller capabilities, you must have an active connection configured.\nNavigate to All \u003e Connections \u0026 Credentials \u003e Connections \u0026 Credential Aliases. Open the record for Amazon Bedrock. Select the Create New Connection \u0026 Credential related link. Enter your Region, such as us-east-1, and your AWS AccessKeyId and SecretAccessKey, and hit Create You should see this screen after succesfull completion Now, you are ready to use use Amazon Bedrock as your provider for Generative AI Controller capabilities in Flow Designer, Virtual Agent Designer, and scripts to create custom experiences with generative AI."
},
{
	"uri": "//localhost:1313/4_servicenow-setup/1_setup_genai_controller_for_bedrock/1.2_select_bedrock_model.html",
	"title": "Select a model for Amazon Bedrock",
	"tags": [],
	"description": "",
	"content": "Select a model for Amazon Bedrock In this section you are going to configure which LLM Model to use with Amazon Bedrock for custom skills. You may have multiple models configured to use with Amazon Bedrock.\nBy default, the settings use Amazon's Titan model, but you can configure the spoke to use a different model by changing the Generative AI Model Config record. In the filter navigator, navigate to the Generative AI Model Config table by entering \"sys_generative_ai_model_config.list\". Click \u0026ldquo;New\u0026rdquo; button Enter the following values\nIn the Model field, enter the ID of the model that you want to use. we are using anthropic.claude-3-sonnet-20240229-v1:0 this value of anthropic claude sonnet model You can find the model ID on the Foundation models \u003e Base models page on Amazon Bedrock. In the Provider field, select Amazon Bedrock In the Connection And Credential Alias field, select Amazon Bedrock connection we created in the previous step Value should be something like this \"sn_amz_bedrock_spk.Amazon_Bedrock\" In the Max Tokens field, update the value to 32768 Click the \"Submit\" button. Now, the Amazon Bedrock spoke is configured to use Claude 3 Sonnet by Anthropic. SUNIL :: Do this step after you build the skill to point to the model Map the chosen model to a custom skill.\nIn the filter navigator, go to the Generative AI Config table by entering sys_generative_ai_config.list. Search for the custom skill you\u0026rsquo;ve created that uses Amazon Bedrock as the service provider, and open the record. The Definition should be OneExtend Capability Definition: . Set the Model field to the model ID you entered in step 3.\n"
},
{
	"uri": "//localhost:1313/4_servicenow-setup/2_knowledge_categorizer.html",
	"title": "Knowledge Article Categorization",
	"tags": [],
	"description": "",
	"content": "Use Case: Knowledge Article Categorization Using NOW Assist Skill kit (NASK) to Automatically Categorize KB Articles This use case covers automating the categorization of Knowledge Base articles at scale. Accurate categorization is crucial for effective self-service experiences, as it allows users to quickly find relevant information and reduces the load on support teams. The core use case involves using the Amazon Bedrock with Anthropic Claude LLM and NASK to process Knowledge articles data. The LLM can intelligently categorize articles by selecting from predefined taxonomy categories within the Knowledge Base. This automated approach streamlines the categorization process for massive article volumes, unlocking greater value from organizational knowledge assets."
},
{
	"uri": "//localhost:1313/4_servicenow-setup/2_knowledge_categorizer/2.1_review_knowledge_articles.html",
	"title": "Review Knowledge Articles",
	"tags": [],
	"description": "",
	"content": "Configure API Credentials for Amazon Bedrock In this section you are going to configure your API credentials (created in Getting Started \u0026gt; section) to use AWS Bedrock in custom workflows and Virtual Agent Designer topics.\nTo use Amazon Bedrock as your LLM provider for Generative AI Controller capabilities, you must have an active connection configured.\nNavigate to All \u003e Connections \u0026 Credentials \u003e Connections \u0026 Credential Aliases. Open the record for Amazon Bedrock. Select the Create New Connection \u0026 Credential related link. Enter your Region, such as us-east-1, and your AWS AccessKeyId and SecretAccessKey, and hit Create You should see this screen after succesfull completion Now, you are ready to use use Amazon Bedrock as your provider for Generative AI Controller capabilities in Flow Designer, Virtual Agent Designer, and scripts to create custom experiences with generative AI."
},
{
	"uri": "//localhost:1313/4_servicenow-setup/2_knowledge_categorizer/2.2_subflow.html",
	"title": "Build Subflow for knowledge categories",
	"tags": [],
	"description": "",
	"content": "Build Subflow to retrieve knowledge categories In this section you are going to configure which LLM Model to use with Amazon Bedrock for custom skills. You may have multiple models configured to use with Amazon Bedrock.\nBy default, the settings use Amazon's Titan model, but you can configure the spoke to use a different model by changing the Generative AI Model Config record. In the filter navigator, navigate to the Generative AI Model Config table by entering \"sys_generative_ai_model_config.list\". Click \u0026ldquo;New\u0026rdquo; button Enter the following values\nIn the Model field, enter the ID of the model that you want to use. we are using anthropic.claude-3-sonnet-20240229-v1:0 this value of anthropic claude sonnet model You can find the model ID on the Foundation models \u003e Base models page on Amazon Bedrock. In the Provider field, select Amazon Bedrock In the Connection And Credential Alias field, select Amazon Bedrock connection we created in the previous step Value should be something like this \"sn_amz_bedrock_spk.Amazon_Bedrock\" In the Max Tokens field, update the value to 32768 Click the \"Submit\" button. Now, the Amazon Bedrock spoke is configured to use Claude 3 Sonnet by Anthropic. SUNIL :: Do this step after you build the skill to point to the model Map the chosen model to a custom skill.\nIn the filter navigator, go to the Generative AI Config table by entering sys_generative_ai_config.list. Search for the custom skill you\u0026rsquo;ve created that uses Amazon Bedrock as the service provider, and open the record. The Definition should be OneExtend Capability Definition: . Set the Model field to the model ID you entered in step 3.\n"
},
{
	"uri": "//localhost:1313/4_servicenow-setup/2_knowledge_categorizer/2.3_custom_skills.html",
	"title": "Custom Skills using NASK",
	"tags": [],
	"description": "",
	"content": "Build Custom skills using NASK In this section you are going to configure your API credentials (created in Getting Started \u0026gt; section) to use AWS Bedrock in custom workflows and Virtual Agent Designer topics.\nTo use Amazon Bedrock as your LLM provider for Generative AI Controller capabilities, you must have an active connection configured.\nNavigate to All \u003e Connections \u0026 Credentials \u003e Connections \u0026 Credential Aliases. Open the record for Amazon Bedrock. Select the Create New Connection \u0026 Credential related link. Enter your Region, such as us-east-1, and your AWS AccessKeyId and SecretAccessKey, and hit Create You should see this screen after succesfull completion Now, you are ready to use use Amazon Bedrock as your provider for Generative AI Controller capabilities in Flow Designer, Virtual Agent Designer, and scripts to create custom experiences with generative AI."
},
{
	"uri": "//localhost:1313/4_servicenow-setup/2_knowledge_categorizer/2.4_skill_in_action.html",
	"title": "See Custom skill in Action",
	"tags": [],
	"description": "",
	"content": "See custom skill in action, on a single KB article In this section you are going to configure which LLM Model to use with Amazon Bedrock for custom skills. You may have multiple models configured to use with Amazon Bedrock.\nBy default, the settings use Amazon's Titan model, but you can configure the spoke to use a different model by changing the Generative AI Model Config record. In the filter navigator, navigate to the Generative AI Model Config table by entering \"sys_generative_ai_model_config.list\". Click \u0026ldquo;New\u0026rdquo; button Enter the following values\nIn the Model field, enter the ID of the model that you want to use. we are using anthropic.claude-3-sonnet-20240229-v1:0 this value of anthropic claude sonnet model You can find the model ID on the Foundation models \u003e Base models page on Amazon Bedrock. In the Provider field, select Amazon Bedrock In the Connection And Credential Alias field, select Amazon Bedrock connection we created in the previous step Value should be something like this \"sn_amz_bedrock_spk.Amazon_Bedrock\" In the Max Tokens field, update the value to 32768 Click the \"Submit\" button. Now, the Amazon Bedrock spoke is configured to use Claude 3 Sonnet by Anthropic. SUNIL :: Do this step after you build the skill to point to the model Map the chosen model to a custom skill.\nIn the filter navigator, go to the Generative AI Config table by entering sys_generative_ai_config.list. Search for the custom skill you\u0026rsquo;ve created that uses Amazon Bedrock as the service provider, and open the record. The Definition should be OneExtend Capability Definition: . Set the Model field to the model ID you entered in step 3.\n"
},
{
	"uri": "//localhost:1313/4_servicenow-setup.html",
	"title": "Setting Up the ServiceNow Now Assist Application",
	"tags": [],
	"description": "Configure the ServiceNow app to integrate with Amazon Bedrock and begin the modernization workflow.",
	"content": "Setting Up the ServiceNow Now Assist Application Now that you‚Äôve enabled the required Amazon Bedrock models, it‚Äôs time to configure the ServiceNow application that interacts with Bedrock.\nThis section walks you through setting up the ServiceNow NOW Assist platform and securely configuring it to call Amazon Bedrock APIs.\nLab Structure These are the steps we will follow to build, deploy and activate a custom skill with NOW Assist Skill Kit (NASK) to implement custom Generative AI action that will automatically categorize the knowledge article. NASK has been designed to easily manage and integrate new skills into the ServiceNow platform via a UI Action and soon into the Now Assist Panel. With NASK you define the input data, leverage tools to process the data, activate the new skill, and deploy it to the platform\nPhase 1 ‚Äì Review knowledge base and gather which categories we want the Now LLM to use to categorize KCS KB article text. Phase 2 ‚Äì Identify and review a specific KCS KB article that we can use as a test record for the custom skill. Phase 3 ‚Äì Using data from Phase 1, build a Subflow that automatically gathers the categories we want the Now LLM to use. Phase 4 ‚Äì Build the custom skill using NASK. Phase 5 ‚Äì Testing the custom skill. Phase 6 ‚Äì Deploying the custom skill. Phase 7 ‚Äì Activating the custom skill. Phase 8 ‚Äì See custom skill in action, on a single KCS KB article. Phase 9 ‚Äì See custom skill in action, on a list of KCS KB article. Navigate to your ServiceNow instance, enter \u0026ldquo;User name\u0026rdquo; and \u0026ldquo;Password\u0026rdquo; and click the \u0026ldquo;Log in\u0026rdquo; button\n"
},
{
	"uri": "//localhost:1313/6_summary.html",
	"title": "Cleanup",
	"tags": [],
	"description": "",
	"content": "Cleanup In order to prevent charges to your account we recommend cleaning up the infrastructure that was created. If you plan to keep things running so you can examine the workshop a bit more please remember to do the cleanup when you are done. It is very easy to leave things running in an AWS account, forget about it, and then accrue charges. Run the command below to remove all of the resources created for this workshop. It may take a few minutes to complete.\nHere are the instructions to delete the resources in the Hosted Event. This will clean up all the workshop resources.\n# Delete CloudFormation Stacks aws cloudformation delete-stack --stack-name $(aws cloudformation list-stacks --stack-status-filter CREATE_COMPLETE UPDATE_COMPLETE --query \u0026#34;StackSummaries[0].StackName\u0026#34; --output text) If you have completed this workshop under your own account, you can follow these steps to remove all of the workshop resources:\n# Delete CloudFormation Stacks aws cloudformation delete-stack --stack-name servicenow Note: you can also head to Cloudformation and select the stack servicenow and click delete stack.\n"
},
{
	"uri": "//localhost:1313/categories.html",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/tags.html",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]